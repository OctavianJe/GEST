{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08475da",
   "metadata": {},
   "source": [
    "# Imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85074372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from gest.data.gest import GEST\n",
    "from gest.service.evaluation.graph_matching.graph import GESTGraph\n",
    "from gest.service.evaluation.graph_matching.similarity import (\n",
    "    SimilarityService,\n",
    "    SimilarityEngine,\n",
    ")\n",
    "from gest.service.evaluation.graph_matching.solver import SolverType\n",
    "from gest.service.evaluation.graph_matching.embedding_type_enum import EmbeddingType\n",
    "\n",
    "DATA_DIR = \"/workspaces/GEST/data\"\n",
    "OUT_DIR = \"/workspaces/GEST/notebooks/data\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "RESULTS_CSV_PATH = os.path.join(\n",
    "    OUT_DIR, \"manual_vs_synthetic_evaluation_graph_matching.csv\"\n",
    ")\n",
    "NEG_RESULTS_CSV_PATH = os.path.join(\n",
    "    OUT_DIR, \"manual_vs_synthetic_evaluation_graph_matching_negatives.csv\"\n",
    ")\n",
    "NEG_PAIRLIST_CSV = os.path.join(OUT_DIR, \"manual_vs_synthetic_negative_pairs_list.csv\")\n",
    "METRICS_CSV_PATH = os.path.join(OUT_DIR, \"graph_matching_detection_metrics.csv\")\n",
    "\n",
    "HIST_BASE_DIR = os.path.join(OUT_DIR, \"histograms\")\n",
    "os.makedirs(HIST_BASE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def hist_path_for(\n",
    "    synthetic_tag: str, config_name: str, ensure_dir: bool = False\n",
    ") -> str:\n",
    "    d = os.path.join(HIST_BASE_DIR, synthetic_tag)\n",
    "    if ensure_dir:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "    return os.path.join(d, f\"hist_{config_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b2807",
   "metadata": {},
   "source": [
    "# Prerequisite - Ensure not having duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8811af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>rows_before</th>\n",
       "      <th>num_dups_removed</th>\n",
       "      <th>rows_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blacklist_eval_gemma3-e2e.csv</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blacklist_eval_gemma3-gest-e2e.csv</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blacklist_eval_gemma3-gest-generation-only.csv</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blacklist_eval_gpt-oss-e2e.csv</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blacklist_eval_gpt-oss-generation-only.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blacklist_eval_gpt-oss-gest-e2e.csv</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blacklist_eval_gpt-oss-gest-generation-only.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gest_eval_gemma3-e2e.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gest_eval_gemma3-gest-e2e.csv</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gest_eval_gemma3-gest-generation-only.csv</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gest_eval_gpt-oss-e2e.csv</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gest_eval_gpt-oss-generation-only.csv</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gest_eval_gpt-oss-gest-e2e.csv</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gest_eval_gpt-oss-gest-generation-only.csv</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file  rows_before  \\\n",
       "0                     blacklist_eval_gemma3-e2e.csv          146   \n",
       "1                blacklist_eval_gemma3-gest-e2e.csv           14   \n",
       "2    blacklist_eval_gemma3-gest-generation-only.csv            3   \n",
       "3                    blacklist_eval_gpt-oss-e2e.csv           35   \n",
       "4        blacklist_eval_gpt-oss-generation-only.csv            1   \n",
       "5               blacklist_eval_gpt-oss-gest-e2e.csv            5   \n",
       "6   blacklist_eval_gpt-oss-gest-generation-only.csv            2   \n",
       "7                          gest_eval_gemma3-e2e.csv            0   \n",
       "8                     gest_eval_gemma3-gest-e2e.csv          133   \n",
       "9         gest_eval_gemma3-gest-generation-only.csv          143   \n",
       "10                        gest_eval_gpt-oss-e2e.csv          114   \n",
       "11            gest_eval_gpt-oss-generation-only.csv          145   \n",
       "12                   gest_eval_gpt-oss-gest-e2e.csv          142   \n",
       "13       gest_eval_gpt-oss-gest-generation-only.csv          144   \n",
       "\n",
       "    num_dups_removed  rows_after  \n",
       "0                  0         146  \n",
       "1                  0          14  \n",
       "2                  0           3  \n",
       "3                  0          35  \n",
       "4                  0           1  \n",
       "5                  0           5  \n",
       "6                  0           2  \n",
       "7                  0           0  \n",
       "8                  0         133  \n",
       "9                  0         143  \n",
       "10                 0         114  \n",
       "11                 0         145  \n",
       "12                 0         142  \n",
       "13                 0         144  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = {\"gest.csv\", \"blacklist.csv\", \"gest_manual.csv\"}\n",
    "patterns = [\"gest*.csv\", \"blacklist*.csv\"]\n",
    "\n",
    "files = sorted(\n",
    "    {\n",
    "        f\n",
    "        for p in patterns\n",
    "        for f in glob.glob(os.path.join(DATA_DIR, p))\n",
    "        if os.path.basename(f) not in exclude\n",
    "    }\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for path in files:\n",
    "    df = pd.read_csv(path)\n",
    "    if not {\"dataset\", \"id\"}.issubset(df.columns):\n",
    "        continue\n",
    "    n_before = len(df)\n",
    "    n_dups = int(df.duplicated([\"dataset\", \"id\"]).sum())\n",
    "    if n_dups:\n",
    "        df = df.drop_duplicates([\"dataset\", \"id\"], keep=\"first\")\n",
    "        df.to_csv(path, index=False)\n",
    "    rows.append((os.path.basename(path), n_before, n_dups, len(df)))\n",
    "\n",
    "pd.DataFrame(\n",
    "    rows, columns=[\"file\", \"rows_before\", \"num_dups_removed\", \"rows_after\"]\n",
    ").sort_values(\"num_dups_removed\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9094c",
   "metadata": {},
   "source": [
    "# Constants & toggles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4b5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_COLUMNS = {\"dataset\", \"id\", \"gest\"}\n",
    "\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# Mean decrease (negatives < positives)\n",
    "ENFORCE_MEAN_DECREASE = False\n",
    "EPS = 1e-9\n",
    "\n",
    "# Skipping / reruns\n",
    "SKIP_COMPLETED_EXPERIMENTS = True  # skip whole configs/experiments if complete\n",
    "FORCE_RERUN = False  # set True to force recompute\n",
    "\n",
    "PLACEHOLDERS = [\"gemma3\", \"gemma3-gest\", \"gpt-oss\", \"gpt-oss-gest\"]\n",
    "VARIANTS = [\"e2e\", \"generation-only\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07dddb1",
   "metadata": {},
   "source": [
    "# Small utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cbe80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _series_or_empty(df: pd.DataFrame, col: str):\n",
    "    \"\"\"Return df[col] if present, else an empty Series aligned to df.index.\"\"\"\n",
    "    if col in df.columns:\n",
    "        return df[col]\n",
    "    return pd.Series([None] * len(df), index=df.index, dtype=object)\n",
    "\n",
    "\n",
    "def ensure_required_columns(df: pd.DataFrame, name: str, required: set):\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{name} missing columns: {sorted(missing)}\")\n",
    "\n",
    "\n",
    "def ensure_unique_pairs(df: pd.DataFrame, name: str):\n",
    "    dup = df.duplicated([\"dataset\", \"id\"], keep=False)\n",
    "    if dup.any():\n",
    "        d = df.loc[dup, [\"dataset\", \"id\"]].value_counts().reset_index(name=\"count\")\n",
    "        raise ValueError(\n",
    "            f\"{name} contains duplicated (dataset,id). Expected unique.\\n\"\n",
    "            f\"Found {len(d)} duplicates:\\n{d.to_string(index=False)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def append_results(csv_path: str, rows: list, header: list):\n",
    "    write_header = not os.path.exists(csv_path)\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header)\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85351a7d",
   "metadata": {},
   "source": [
    "# Load manual & pre-parse graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d11218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Manual GESTs: 100%|██████████| 146/146 [00:00<00:00, 345.39it/s]\n"
     ]
    }
   ],
   "source": [
    "manual = pd.read_csv(os.path.join(DATA_DIR, \"gest_manual.csv\"))\n",
    "ensure_required_columns(manual, \"manual\", REQUIRED_COLUMNS)\n",
    "ensure_unique_pairs(manual, \"manual\")\n",
    "\n",
    "tqdm.pandas(desc=\"Parsing Manual GESTs\")\n",
    "manual[\"g1\"] = manual[\"gest\"].progress_apply(\n",
    "    lambda s: GESTGraph(gest=GEST.model_validate_json(s))\n",
    ")\n",
    "manual_key = {(r.dataset, r.id): r for r in manual.itertuples(index=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651e0ee",
   "metadata": {},
   "source": [
    "# Build/load shared negatives + expected counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad9e7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 146 shared NEGATIVE pairs (from manual ids).\n",
      "Expected rows per (synthetic, config): POS=146, NEG=146\n"
     ]
    }
   ],
   "source": [
    "def build_or_load_negative_pairs_from_manual(\n",
    "    manual_df: pd.DataFrame, csv_path: str, seed: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    if os.path.exists(csv_path):\n",
    "        neg_list = pd.read_csv(csv_path)\n",
    "        need = {\"dataset\", \"id_left\", \"id_right\"}\n",
    "        if not need.issubset(neg_list.columns):\n",
    "            raise ValueError(\n",
    "                f\"Negative pair list missing columns: {need - set(neg_list.columns)}\"\n",
    "            )\n",
    "        return neg_list\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    for dataset, g in manual_df.groupby(\"dataset\", dropna=False):\n",
    "        ids = sorted(g[\"id\"].unique().tolist())\n",
    "        if len(ids) < 2:\n",
    "            continue\n",
    "        n_pos = len(ids)  # balance\n",
    "        candidates = [(i, j) for i in ids for j in ids if i != j]\n",
    "        n_take = min(n_pos, len(candidates))\n",
    "        idx = rng.choice(len(candidates), size=n_take, replace=False)\n",
    "        for k in idx:\n",
    "            i, j = candidates[k]\n",
    "            rows.append({\"dataset\": dataset, \"id_left\": i, \"id_right\": j})\n",
    "    neg_list = pd.DataFrame(rows)\n",
    "    if neg_list.empty:\n",
    "        raise ValueError(\"Could not create any negative pairs from manual.\")\n",
    "    neg_list.to_csv(csv_path, index=False)\n",
    "    print(f\"Built and saved {len(neg_list)} NEGATIVE pairs at: {csv_path}\")\n",
    "    return neg_list\n",
    "\n",
    "\n",
    "negative_pairs = build_or_load_negative_pairs_from_manual(\n",
    "    manual, NEG_PAIRLIST_CSV, seed=RNG_SEED\n",
    ")\n",
    "print(f\"Using {len(negative_pairs)} shared NEGATIVE pairs (from manual ids).\")\n",
    "\n",
    "\n",
    "def expected_counts(\n",
    "    manual_df: pd.DataFrame, neg_pairs_df: pd.DataFrame\n",
    ") -> tuple[int, int]:\n",
    "    n_pos = int(len(manual_df))  # one pos per manual id\n",
    "    n_neg = int(len(neg_pairs_df))  # one neg per (dataset,id_left,id_right)\n",
    "    return n_pos, n_neg\n",
    "\n",
    "\n",
    "EXPECTED_POS, EXPECTED_NEG = expected_counts(manual, negative_pairs)\n",
    "print(f\"Expected rows per (synthetic, config): POS={EXPECTED_POS}, NEG={EXPECTED_NEG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bdf286",
   "metadata": {},
   "source": [
    "# Discover experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2c6fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments to run:\n",
      " - standard: gest.csv\n",
      " - gemma3-e2e: gest_eval_gemma3-e2e.csv  [blacklist: blacklist_eval_gemma3-e2e.csv]\n",
      " - gemma3-gest-e2e: gest_eval_gemma3-gest-e2e.csv  [blacklist: blacklist_eval_gemma3-gest-e2e.csv]\n",
      " - gemma3-gest-generation-only: gest_eval_gemma3-gest-generation-only.csv  [blacklist: blacklist_eval_gemma3-gest-generation-only.csv]\n",
      " - gpt-oss-e2e: gest_eval_gpt-oss-e2e.csv  [blacklist: blacklist_eval_gpt-oss-e2e.csv]\n",
      " - gpt-oss-generation-only: gest_eval_gpt-oss-generation-only.csv  [blacklist: blacklist_eval_gpt-oss-generation-only.csv]\n",
      " - gpt-oss-gest-e2e: gest_eval_gpt-oss-gest-e2e.csv  [blacklist: blacklist_eval_gpt-oss-gest-e2e.csv]\n",
      " - gpt-oss-gest-generation-only: gest_eval_gpt-oss-gest-generation-only.csv  [blacklist: blacklist_eval_gpt-oss-gest-generation-only.csv]\n"
     ]
    }
   ],
   "source": [
    "def discover_experiments():\n",
    "    exps = []\n",
    "\n",
    "    # Baseline\n",
    "    standard_path = os.path.join(DATA_DIR, \"gest.csv\")\n",
    "    if os.path.exists(standard_path):\n",
    "        exps.append(\n",
    "            {\n",
    "                \"synthetic_tag\": \"standard\",\n",
    "                \"synthetic_path\": standard_path,\n",
    "                \"blacklist_path\": None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Pattern-based\n",
    "    for ph in PLACEHOLDERS:\n",
    "        for var in VARIANTS:\n",
    "            syn = os.path.join(DATA_DIR, f\"gest_eval_{ph}-{var}.csv\")\n",
    "            bl = os.path.join(DATA_DIR, f\"blacklist_eval_{ph}-{var}.csv\")\n",
    "            if os.path.exists(syn):\n",
    "                exps.append(\n",
    "                    {\n",
    "                        \"synthetic_tag\": f\"{ph}-{var}\",\n",
    "                        \"synthetic_path\": syn,\n",
    "                        \"blacklist_path\": bl if os.path.exists(bl) else None,\n",
    "                    }\n",
    "                )\n",
    "    return exps\n",
    "\n",
    "\n",
    "EXPERIMENTS = discover_experiments()\n",
    "if not EXPERIMENTS:\n",
    "    raise RuntimeError(\"No synthetic experiments found.\")\n",
    "\n",
    "print(\"Experiments to run:\")\n",
    "for e in EXPERIMENTS:\n",
    "    print(\n",
    "        f\" - {e['synthetic_tag']}: {os.path.basename(e['synthetic_path'])}\"\n",
    "        + (\n",
    "            f\"  [blacklist: {os.path.basename(e['blacklist_path'])}]\"\n",
    "            if e[\"blacklist_path\"]\n",
    "            else \"\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447bed27",
   "metadata": {},
   "source": [
    "# Graph matching configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0963f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    {\n",
    "        \"name\": \"Spectral_GloVe300\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.SPECTRAL,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE300,\n",
    "            \"use_edges\": True,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NGM_GloVe300\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.NGM,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE300,\n",
    "            \"use_edges\": True,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Spectral_GloVe300_NoEdges\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.SPECTRAL,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE300,\n",
    "            \"use_edges\": False,\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb2ce3",
   "metadata": {},
   "source": [
    "# More helpers (blacklist, align/dedupe, skipping, scores IO, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b65f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_blacklist_set(blacklist_path: str | None):\n",
    "    if not blacklist_path or not os.path.exists(blacklist_path):\n",
    "        return set()\n",
    "    b = pd.read_csv(blacklist_path)\n",
    "    need = {\"dataset\", \"id\"}\n",
    "    if not need.issubset(b.columns):\n",
    "        raise ValueError(\n",
    "            f\"Blacklist {blacklist_path} missing columns {need - set(b.columns)}\"\n",
    "        )\n",
    "    return set(zip(b[\"dataset\"], b[\"id\"]))\n",
    "\n",
    "\n",
    "def align_and_dedupe_synthetic(\n",
    "    synthetic_df: pd.DataFrame, manual_df: pd.DataFrame, tag: str\n",
    "):\n",
    "    manual_keys = manual_df[[\"dataset\", \"id\"]].drop_duplicates()\n",
    "    syn = synthetic_df.merge(\n",
    "        manual_keys.assign(_keep=1), on=[\"dataset\", \"id\"], how=\"inner\"\n",
    "    )\n",
    "\n",
    "    dup_mask = syn.duplicated([\"dataset\", \"id\"], keep=False)\n",
    "    dup_report = (\n",
    "        syn.loc[dup_mask, [\"dataset\", \"id\"]]\n",
    "        .value_counts()\n",
    "        .reset_index(name=\"count\")\n",
    "        .sort_values([\"dataset\", \"id\"])\n",
    "    )\n",
    "\n",
    "    syn_dedup = (\n",
    "        syn.sort_values([\"dataset\", \"id\"])\n",
    "        .drop_duplicates([\"dataset\", \"id\"], keep=\"first\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if not dup_report.empty:\n",
    "        report_path = os.path.join(OUT_DIR, f\"dedupe_report_{tag}.csv\")\n",
    "        dup_report.to_csv(report_path, index=False)\n",
    "        print(\n",
    "            f\"[{tag}] Collapsed {len(dup_report)} duplicated keys after aligning to manual. Report → {report_path}\"\n",
    "        )\n",
    "\n",
    "    return syn_dedup, dup_report\n",
    "\n",
    "\n",
    "def load_config_scores(pos_path, neg_path, config_name, synthetic_tag):\n",
    "    pos = pd.read_csv(pos_path) if os.path.exists(pos_path) else pd.DataFrame()\n",
    "    neg = pd.read_csv(neg_path) if os.path.exists(neg_path) else pd.DataFrame()\n",
    "    if not pos.empty:\n",
    "        syn_col = _series_or_empty(pos, \"synthetic\")\n",
    "        cfg_col = _series_or_empty(pos, \"configuration\")\n",
    "        pos = pos[(syn_col == synthetic_tag) & (cfg_col == config_name)]\n",
    "    if not neg.empty:\n",
    "        syn_col = _series_or_empty(neg, \"synthetic\")\n",
    "        cfg_col = _series_or_empty(neg, \"configuration\")\n",
    "        neg = neg[(syn_col == synthetic_tag) & (cfg_col == config_name)]\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "def config_completion_status(\n",
    "    synthetic_tag: str, config_name: str, expected_pos: int, expected_neg: int\n",
    ") -> dict:\n",
    "    pos = (\n",
    "        pd.read_csv(RESULTS_CSV_PATH)\n",
    "        if os.path.exists(RESULTS_CSV_PATH)\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "    neg = (\n",
    "        pd.read_csv(NEG_RESULTS_CSV_PATH)\n",
    "        if os.path.exists(NEG_RESULTS_CSV_PATH)\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "    met = (\n",
    "        pd.read_csv(METRICS_CSV_PATH)\n",
    "        if os.path.exists(METRICS_CSV_PATH)\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "\n",
    "    syn_col = _series_or_empty(pos, \"synthetic\")\n",
    "    cfg_col = _series_or_empty(pos, \"configuration\")\n",
    "    pos = pos[(syn_col == synthetic_tag) & (cfg_col == config_name)]\n",
    "\n",
    "    syn_col = _series_or_empty(neg, \"synthetic\")\n",
    "    cfg_col = _series_or_empty(neg, \"configuration\")\n",
    "    neg = neg[(syn_col == synthetic_tag) & (cfg_col == config_name)]\n",
    "\n",
    "    syn_col = _series_or_empty(met, \"synthetic\")\n",
    "    cfg_col = _series_or_empty(met, \"configuration\")\n",
    "    met = met[(syn_col == synthetic_tag) & (cfg_col == config_name)]\n",
    "\n",
    "    pos_ok = len(pos) >= expected_pos\n",
    "    neg_ok = len(neg) >= expected_neg\n",
    "    hist_path = hist_path_for(synthetic_tag, config_name, ensure_dir=False)\n",
    "    hist_ok = os.path.exists(hist_path)\n",
    "    metrics_ok = len(met) > 0\n",
    "\n",
    "    return {\n",
    "        \"pos_count\": len(pos),\n",
    "        \"neg_count\": len(neg),\n",
    "        \"pos_ok\": pos_ok,\n",
    "        \"neg_ok\": neg_ok,\n",
    "        \"metrics_ok\": metrics_ok,\n",
    "        \"hist_ok\": hist_ok,\n",
    "        \"hist_path\": hist_path,\n",
    "    }\n",
    "\n",
    "\n",
    "def config_is_complete(status: dict) -> bool:\n",
    "    return bool(\n",
    "        status[\"pos_ok\"]\n",
    "        and status[\"neg_ok\"]\n",
    "        and status[\"metrics_ok\"]\n",
    "        and status[\"hist_ok\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def experiment_is_complete(\n",
    "    synthetic_tag: str, expected_pos: int, expected_neg: int\n",
    ") -> tuple[bool, dict]:\n",
    "    all_ok, details = True, {}\n",
    "    for cfg in configurations:\n",
    "        st = config_completion_status(\n",
    "            synthetic_tag, cfg[\"name\"], expected_pos, expected_neg\n",
    "        )\n",
    "        details[cfg[\"name\"]] = st\n",
    "        all_ok = all_ok and config_is_complete(st)\n",
    "    return all_ok, details\n",
    "\n",
    "\n",
    "def print_experiment_status(synthetic_tag: str, details: dict):\n",
    "    print(f\"[{synthetic_tag}] completion status:\")\n",
    "    for cfg_name, st in details.items():\n",
    "        flags = \"OK\" if config_is_complete(st) else \"INCOMPLETE\"\n",
    "        print(\n",
    "            f\"  - {cfg_name}: {flags} | pos {st['pos_count']}/{'✓' if st['pos_ok'] else '✗'}, \"\n",
    "            f\"neg {st['neg_count']}/{'✓' if st['neg_ok'] else '✗'}, \"\n",
    "            f\"metrics {'✓' if st['metrics_ok'] else '✗'}, hist {'✓' if st['hist_ok'] else '✗'}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def compute_similarity_safe(\n",
    "    similarity_service, g1, g2, dataset, id_left, id_right=None, blacklisted=False\n",
    "):\n",
    "    # Treat None/NaN/blacklisted as GS = 0\n",
    "    if g1 is None:\n",
    "        return 0.0\n",
    "    if g2 is None or (isinstance(g2, float) and np.isnan(g2)) or blacklisted:\n",
    "        return 0.0\n",
    "    try:\n",
    "        return similarity_service.graph_similarity_normalized(g1, g2)\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"Exception on (dataset={dataset}, id_left={id_left}, id_right={id_right}): {e}\"\n",
    "        )\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d25123",
   "metadata": {},
   "source": [
    "# Metrics computation & plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f76a41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _best_accuracy_threshold(y_true: np.ndarray, y_score: np.ndarray) -> float:\n",
    "    uniq = np.unique(y_score)\n",
    "    if len(uniq) == 1:\n",
    "        return float(uniq[0])\n",
    "    uniq_sorted = np.sort(uniq)\n",
    "    mids = (uniq_sorted[:-1] + uniq_sorted[1:]) / 2.0\n",
    "    candidates = np.concatenate(\n",
    "        ([uniq_sorted[0] - 1e-12], mids, [uniq_sorted[-1] + 1e-12])\n",
    "    )\n",
    "    accs = []\n",
    "    for thr in candidates:\n",
    "        y_pred = (y_score >= thr).astype(int)\n",
    "        accs.append((y_pred == y_true).mean())\n",
    "    max_acc = np.max(accs)\n",
    "    best = np.array(candidates)[np.isclose(accs, max_acc)]\n",
    "    return float(np.median(best))\n",
    "\n",
    "\n",
    "def evaluate_and_save_metrics(\n",
    "    config_name: str, synthetic_tag: str, pos_df: pd.DataFrame, neg_df: pd.DataFrame\n",
    "):\n",
    "    if pos_df.empty or neg_df.empty:\n",
    "        print(\n",
    "            f\"[{synthetic_tag} | {config_name}] Skipping metrics: missing scores (pos: {len(pos_df)}, neg: {len(neg_df)})\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    pos_scores = pos_df[\"similarity\"].to_numpy()\n",
    "    neg_scores = neg_df[\"similarity\"].to_numpy()\n",
    "\n",
    "    # Before/After means\n",
    "    mean_before = float(np.mean(pos_scores)) if len(pos_scores) else 0.0\n",
    "    mean_after = float(np.mean(neg_scores)) if len(neg_scores) else 0.0\n",
    "    mean_delta = float(mean_before - mean_after)\n",
    "    mean_ok = bool((mean_after + EPS) < mean_before)\n",
    "    if not mean_ok:\n",
    "        msg = f\"[{synthetic_tag} | {config_name}] WARNING: Mean after ({mean_after:.6f}) !< before ({mean_before:.6f}).\"\n",
    "        if ENFORCE_MEAN_DECREASE:\n",
    "            raise AssertionError(msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    # Metrics\n",
    "    y_true = np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_scores)])\n",
    "    y_score = np.concatenate([pos_scores, neg_scores])\n",
    "\n",
    "    auprc = float(average_precision_score(y_true, y_score))\n",
    "    corr = (\n",
    "        0.0\n",
    "        if np.allclose(np.std(y_score), 0.0)\n",
    "        else float(np.corrcoef(y_true, y_score)[0, 1])\n",
    "    )\n",
    "\n",
    "    mu_pos = float(np.mean(pos_scores)) if len(pos_scores) > 0 else 0.0\n",
    "    mu_neg = float(np.mean(neg_scores)) if len(neg_scores) > 0 else 0.0\n",
    "    var_pos = float(np.var(pos_scores, ddof=1)) if len(pos_scores) > 1 else 0.0\n",
    "    var_neg = float(np.var(neg_scores, ddof=1)) if len(neg_scores) > 1 else 0.0\n",
    "    denom = var_pos + var_neg\n",
    "    fisher = float(((mu_pos - mu_neg) ** 2) / denom) if denom > 0 else 0.0\n",
    "\n",
    "    thr_acc = _best_accuracy_threshold(y_true, y_score)\n",
    "    y_pred = (y_score >= thr_acc).astype(int)\n",
    "    accuracy = float((y_pred == y_true).mean())\n",
    "\n",
    "    # Save metrics\n",
    "    metrics_row = {\n",
    "        \"synthetic\": synthetic_tag,\n",
    "        \"configuration\": config_name,\n",
    "        \"n_pos\": int(len(pos_scores)),\n",
    "        \"n_neg\": int(len(neg_scores)),\n",
    "        \"MeanGS_Before_Pos\": mean_before,\n",
    "        \"MeanGS_After_Neg\": mean_after,\n",
    "        \"MeanGS_Delta\": mean_delta,\n",
    "        \"MeanDecrease_OK\": int(mean_ok),\n",
    "        \"threshold_acc\": thr_acc,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Correlation\": corr,\n",
    "        \"FisherScore\": fisher,\n",
    "        \"AUPRC\": auprc,\n",
    "    }\n",
    "    write_header = not os.path.exists(METRICS_CSV_PATH)\n",
    "    with open(METRICS_CSV_PATH, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=list(metrics_row.keys()))\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics_row)\n",
    "\n",
    "    # Histogram (per experiment folder)\n",
    "    plt.figure()\n",
    "    plt.hist(pos_scores, bins=30, alpha=0.5, label=\"Positives (same story)\")\n",
    "    plt.hist(neg_scores, bins=30, alpha=0.5, label=\"Negatives (different story)\")\n",
    "    plt.axvline(thr_acc, linestyle=\"--\", label=f\"Acc-best thr={thr_acc:.3f}\")\n",
    "    plt.title(f\"GS distribution: {synthetic_tag} | {config_name}\")\n",
    "    plt.xlabel(\"Graph Similarity (GS)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    hist_path = hist_path_for(synthetic_tag, config_name, ensure_dir=True)\n",
    "    plt.savefig(hist_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\n",
    "        f\"[{synthetic_tag} | {config_name}] Means → before: {mean_before:.6f}, after: {mean_after:.6f}, delta: {mean_delta:.6f}\"\n",
    "    )\n",
    "    print(f\"[{synthetic_tag} | {config_name}] Metrics saved → {METRICS_CSV_PATH}\")\n",
    "    print(f\"[{synthetic_tag} | {config_name}] Histogram saved → {hist_path}\")\n",
    "    return metrics_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76cf646",
   "metadata": {},
   "source": [
    "# Main loop (experiments × configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c567f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[standard] completion status:\n",
      "  - Spectral_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - NGM_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - Spectral_GloVe300_NoEdges: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "[standard] All configurations complete — skipping.\n",
      "[gemma3-e2e] completion status:\n",
      "  - Spectral_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - NGM_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - Spectral_GloVe300_NoEdges: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "[gemma3-e2e] All configurations complete — skipping.\n",
      "[gemma3-gest-e2e] completion status:\n",
      "  - Spectral_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - NGM_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - Spectral_GloVe300_NoEdges: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "[gemma3-gest-e2e] All configurations complete — skipping.\n",
      "[gemma3-gest-generation-only] completion status:\n",
      "  - Spectral_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - NGM_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - Spectral_GloVe300_NoEdges: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "[gemma3-gest-generation-only] All configurations complete — skipping.\n",
      "[gpt-oss-e2e] completion status:\n",
      "  - Spectral_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - NGM_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - Spectral_GloVe300_NoEdges: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "[gpt-oss-e2e] All configurations complete — skipping.\n",
      "[gpt-oss-generation-only] completion status:\n",
      "  - Spectral_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - NGM_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - Spectral_GloVe300_NoEdges: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "[gpt-oss-generation-only] All configurations complete — skipping.\n",
      "[gpt-oss-gest-e2e] completion status:\n",
      "  - Spectral_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - NGM_GloVe300: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "  - Spectral_GloVe300_NoEdges: OK | pos 146/✓, neg 146/✓, metrics ✓, hist ✓\n",
      "[gpt-oss-gest-e2e] All configurations complete — skipping.\n",
      "[gpt-oss-gest-generation-only] completion status:\n",
      "  - Spectral_GloVe300: INCOMPLETE | pos 0/✗, neg 0/✗, metrics ✗, hist ✗\n",
      "  - NGM_GloVe300: INCOMPLETE | pos 0/✗, neg 0/✗, metrics ✗, hist ✗\n",
      "  - Spectral_GloVe300_NoEdges: INCOMPLETE | pos 0/✗, neg 0/✗, metrics ✗, hist ✗\n",
      "\n",
      "=== Experiment: gpt-oss-gest-generation-only ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Synthetic GESTs (gpt-oss-gest-generation-only): 100%|██████████| 146/146 [00:00<00:00, 1955.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- gpt-oss-gest-generation-only | Spectral_GloVe300 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Positives gpt-oss-gest-generation-only | Spectral_GloVe300: 100%|██████████| 146/146 [00:15<00:00,  9.30it/s]\n",
      "Negatives gpt-oss-gest-generation-only | Spectral_GloVe300: 100%|██████████| 146/146 [00:22<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-oss-gest-generation-only | Spectral_GloVe300] Means → before: 0.674209, after: 0.244251, delta: 0.429958\n",
      "[gpt-oss-gest-generation-only | Spectral_GloVe300] Metrics saved → /workspaces/GEST/notebooks/data/graph_matching_detection_metrics.csv\n",
      "[gpt-oss-gest-generation-only | Spectral_GloVe300] Histogram saved → /workspaces/GEST/notebooks/data/histograms/gpt-oss-gest-generation-only/hist_Spectral_GloVe300.png\n",
      "\n",
      "--- gpt-oss-gest-generation-only | NGM_GloVe300 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Positives gpt-oss-gest-generation-only | NGM_GloVe300: 100%|██████████| 146/146 [00:14<00:00,  9.79it/s]\n",
      "Negatives gpt-oss-gest-generation-only | NGM_GloVe300: 100%|██████████| 146/146 [00:18<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-oss-gest-generation-only | NGM_GloVe300] Means → before: 0.477941, after: 0.082199, delta: 0.395742\n",
      "[gpt-oss-gest-generation-only | NGM_GloVe300] Metrics saved → /workspaces/GEST/notebooks/data/graph_matching_detection_metrics.csv\n",
      "[gpt-oss-gest-generation-only | NGM_GloVe300] Histogram saved → /workspaces/GEST/notebooks/data/histograms/gpt-oss-gest-generation-only/hist_NGM_GloVe300.png\n",
      "\n",
      "--- gpt-oss-gest-generation-only | Spectral_GloVe300_NoEdges ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Positives gpt-oss-gest-generation-only | Spectral_GloVe300_NoEdges: 100%|██████████| 146/146 [00:01<00:00, 78.04it/s] \n",
      "Negatives gpt-oss-gest-generation-only | Spectral_GloVe300_NoEdges: 100%|██████████| 146/146 [00:01<00:00, 79.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-oss-gest-generation-only | Spectral_GloVe300_NoEdges] Means → before: 0.927335, after: 0.526797, delta: 0.400538\n",
      "[gpt-oss-gest-generation-only | Spectral_GloVe300_NoEdges] Metrics saved → /workspaces/GEST/notebooks/data/graph_matching_detection_metrics.csv\n",
      "[gpt-oss-gest-generation-only | Spectral_GloVe300_NoEdges] Histogram saved → /workspaces/GEST/notebooks/data/histograms/gpt-oss-gest-generation-only/hist_Spectral_GloVe300_NoEdges.png\n",
      "\n",
      "All experiments done.\n"
     ]
    }
   ],
   "source": [
    "for exp in EXPERIMENTS:\n",
    "    # Skip entire experiment if all configs complete\n",
    "    if SKIP_COMPLETED_EXPERIMENTS and not FORCE_RERUN:\n",
    "        done, details = experiment_is_complete(\n",
    "            exp[\"synthetic_tag\"], EXPECTED_POS, EXPECTED_NEG\n",
    "        )\n",
    "        print_experiment_status(exp[\"synthetic_tag\"], details)\n",
    "        if done:\n",
    "            print(f\"[{exp['synthetic_tag']}] All configurations complete — skipping.\")\n",
    "            continue\n",
    "\n",
    "    synthetic_tag = exp[\"synthetic_tag\"]\n",
    "    synthetic_path = exp[\"synthetic_path\"]\n",
    "    blacklist_set = load_blacklist_set(exp[\"blacklist_path\"])\n",
    "\n",
    "    print(f\"\\n=== Experiment: {synthetic_tag} ===\")\n",
    "\n",
    "    # Load & align synthetic to manual, dedupe keys\n",
    "    synthetic = pd.read_csv(synthetic_path)\n",
    "    ensure_required_columns(synthetic, synthetic_tag, REQUIRED_COLUMNS)\n",
    "    synthetic_use, _dup = align_and_dedupe_synthetic(synthetic, manual, synthetic_tag)\n",
    "\n",
    "    # Merge: keep all manual ids; mark missing/blacklisted synthetic\n",
    "    pairs = pd.merge(\n",
    "        manual[[\"dataset\", \"id\", \"gest\", \"g1\"]],\n",
    "        synthetic_use[[\"dataset\", \"id\", \"gest\"]].rename(\n",
    "            columns={\"gest\": \"gest_synthetic\"}\n",
    "        ),\n",
    "        on=[\"dataset\", \"id\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Flags\n",
    "    pairs[\"is_blacklisted\"] = [\n",
    "        (d, i) in blacklist_set for d, i in zip(pairs[\"dataset\"], pairs[\"id\"])\n",
    "    ]\n",
    "    pairs[\"has_syn\"] = ~pairs[\"gest_synthetic\"].isna()\n",
    "\n",
    "    # Build g2 safely (parse errors -> None)\n",
    "    def build_g2(row):\n",
    "        if (not row[\"has_syn\"]) or row[\"is_blacklisted\"]:\n",
    "            return None\n",
    "        try:\n",
    "            return GESTGraph(gest=GEST.model_validate_json(row[\"gest_synthetic\"]))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    tqdm.pandas(desc=f\"Parsing Synthetic GESTs ({synthetic_tag})\")\n",
    "    pairs[\"g2\"] = pairs.progress_apply(build_g2, axis=1)  # type: ignore\n",
    "    pairs[\"invalid_synthetic\"] = (\n",
    "        pairs[\"has_syn\"] & (~pairs[\"is_blacklisted\"]) & pairs[\"g2\"].isna()\n",
    "    )\n",
    "\n",
    "    # For negatives lookup\n",
    "    syn_g2_by_key = {(r.dataset, r.id): r.g2 for r in pairs.itertuples(index=False)}\n",
    "\n",
    "    # Run each configuration\n",
    "    for config in configurations:\n",
    "        config_name = config[\"name\"]\n",
    "\n",
    "        # Skip config if complete\n",
    "        if SKIP_COMPLETED_EXPERIMENTS and not FORCE_RERUN:\n",
    "            st = config_completion_status(\n",
    "                synthetic_tag, config_name, EXPECTED_POS, EXPECTED_NEG\n",
    "            )\n",
    "            if config_is_complete(st):\n",
    "                print(\n",
    "                    f\"--- {synthetic_tag} | {config_name} already complete — skipping.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        print(f\"\\n--- {synthetic_tag} | {config_name} ---\")\n",
    "        engine = SimilarityEngine(**config[\"engine_params\"])\n",
    "        similarity_service = SimilarityService(engine=engine)\n",
    "\n",
    "        # Resume POSITIVES\n",
    "        processed_pos = set()\n",
    "        if os.path.exists(RESULTS_CSV_PATH):\n",
    "            temp = pd.read_csv(RESULTS_CSV_PATH)\n",
    "            temp = temp[\n",
    "                (temp.get(\"configuration\", \"\") == config_name)\n",
    "                & (temp.get(\"synthetic\", \"\") == synthetic_tag)\n",
    "            ]\n",
    "            processed_pos = set(zip(temp[\"dataset\"], temp[\"id\"]))\n",
    "\n",
    "        pairs[\"is_processed_pos\"] = [\n",
    "            (d, i) in processed_pos for d, i in zip(pairs[\"dataset\"], pairs[\"id\"])\n",
    "        ]\n",
    "        pos_to_process = pairs[~pairs[\"is_processed_pos\"]].copy()\n",
    "\n",
    "        if not pos_to_process.empty:\n",
    "            pos_rows = []\n",
    "            for r in tqdm(\n",
    "                pos_to_process.itertuples(index=False),\n",
    "                total=len(pos_to_process),\n",
    "                desc=f\"Positives {synthetic_tag} | {config_name}\",\n",
    "            ):\n",
    "                black_or_missing_or_invalid = bool(\n",
    "                    r.is_blacklisted or (not r.has_syn) or pd.isna(r.g2)\n",
    "                )\n",
    "                score = compute_similarity_safe(\n",
    "                    similarity_service,\n",
    "                    r.g1,\n",
    "                    (None if pd.isna(r.g2) else r.g2),\n",
    "                    r.dataset,\n",
    "                    r.id,\n",
    "                    None,\n",
    "                    blacklisted=black_or_missing_or_invalid,\n",
    "                )\n",
    "                pos_rows.append(\n",
    "                    {\n",
    "                        \"synthetic\": synthetic_tag,\n",
    "                        \"dataset\": r.dataset,\n",
    "                        \"id\": r.id,\n",
    "                        \"configuration\": config_name,\n",
    "                        \"similarity\": score,\n",
    "                        \"label\": 1,\n",
    "                        \"pair_type\": \"positive\",\n",
    "                        \"blacklisted_or_missing_or_invalid\": int(\n",
    "                            black_or_missing_or_invalid\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "            append_results(\n",
    "                RESULTS_CSV_PATH,\n",
    "                pos_rows,\n",
    "                header=[\n",
    "                    \"synthetic\",\n",
    "                    \"dataset\",\n",
    "                    \"id\",\n",
    "                    \"configuration\",\n",
    "                    \"similarity\",\n",
    "                    \"label\",\n",
    "                    \"pair_type\",\n",
    "                    \"blacklisted_or_missing_or_invalid\",\n",
    "                ],\n",
    "            )\n",
    "        else:\n",
    "            print(\"All POSITIVE pairs already processed.\")\n",
    "\n",
    "        # Resume NEGATIVES\n",
    "        processed_neg = set()\n",
    "        if os.path.exists(NEG_RESULTS_CSV_PATH):\n",
    "            tempn = pd.read_csv(NEG_RESULTS_CSV_PATH)\n",
    "            tempn = tempn[\n",
    "                (tempn.get(\"configuration\", \"\") == config_name)\n",
    "                & (tempn.get(\"synthetic\", \"\") == synthetic_tag)\n",
    "            ]\n",
    "            processed_neg = set(\n",
    "                zip(tempn[\"dataset\"], tempn[\"id_left\"], tempn[\"id_right\"])\n",
    "            )\n",
    "\n",
    "        neg_to_process = [\n",
    "            r\n",
    "            for r in negative_pairs.itertuples(index=False)\n",
    "            if (r.dataset, r.id_left, r.id_right) not in processed_neg\n",
    "        ]\n",
    "\n",
    "        if neg_to_process:\n",
    "            neg_rows = []\n",
    "            for r in tqdm(\n",
    "                neg_to_process,\n",
    "                total=len(neg_to_process),\n",
    "                desc=f\"Negatives {synthetic_tag} | {config_name}\",\n",
    "            ):\n",
    "                left_manual = manual_key.get((r.dataset, r.id_left))\n",
    "                g1 = left_manual.g1 if left_manual is not None else None\n",
    "\n",
    "                g2_raw = syn_g2_by_key.get((r.dataset, r.id_right), None)\n",
    "                g2 = (\n",
    "                    None\n",
    "                    if (\n",
    "                        g2_raw is None\n",
    "                        or (isinstance(g2_raw, float) and np.isnan(g2_raw))\n",
    "                    )\n",
    "                    else g2_raw\n",
    "                )\n",
    "\n",
    "                right_in_blacklist = (r.dataset, r.id_right) in blacklist_set\n",
    "                right_missing_key = (r.dataset, r.id_right) not in syn_g2_by_key\n",
    "                right_invalid = g2 is None\n",
    "                right_blacklisted_or_missing_or_invalid = (\n",
    "                    right_in_blacklist or right_missing_key or right_invalid\n",
    "                )\n",
    "\n",
    "                score = compute_similarity_safe(\n",
    "                    similarity_service,\n",
    "                    g1,\n",
    "                    g2,\n",
    "                    r.dataset,\n",
    "                    r.id_left,\n",
    "                    r.id_right,\n",
    "                    blacklisted=right_blacklisted_or_missing_or_invalid,\n",
    "                )\n",
    "                neg_rows.append(\n",
    "                    {\n",
    "                        \"synthetic\": synthetic_tag,\n",
    "                        \"dataset\": r.dataset,\n",
    "                        \"id_left\": r.id_left,\n",
    "                        \"id_right\": r.id_right,\n",
    "                        \"configuration\": config_name,\n",
    "                        \"similarity\": score,\n",
    "                        \"label\": 0,\n",
    "                        \"pair_type\": \"negative\",\n",
    "                        \"blacklisted_or_missing_or_invalid\": int(\n",
    "                            right_blacklisted_or_missing_or_invalid\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "            append_results(\n",
    "                NEG_RESULTS_CSV_PATH,\n",
    "                neg_rows,\n",
    "                header=[\n",
    "                    \"synthetic\",\n",
    "                    \"dataset\",\n",
    "                    \"id_left\",\n",
    "                    \"id_right\",\n",
    "                    \"configuration\",\n",
    "                    \"similarity\",\n",
    "                    \"label\",\n",
    "                    \"pair_type\",\n",
    "                    \"blacklisted_or_missing_or_invalid\",\n",
    "                ],\n",
    "            )\n",
    "        else:\n",
    "            print(\"All NEGATIVE pairs already processed.\")\n",
    "\n",
    "        # Metrics & histogram\n",
    "        pos_scores_df, neg_scores_df = load_config_scores(\n",
    "            RESULTS_CSV_PATH, NEG_RESULTS_CSV_PATH, config_name, synthetic_tag\n",
    "        )\n",
    "        evaluate_and_save_metrics(\n",
    "            config_name, synthetic_tag, pos_scores_df, neg_scores_df\n",
    "        )\n",
    "\n",
    "print(\"\\nAll experiments done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
