{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27e5df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from gest.data.gest import GEST\n",
    "from gest.service.evaluation.graph_matching.graph import GESTGraph\n",
    "from gest.service.evaluation.graph_matching.similarity import (\n",
    "    SimilarityService,\n",
    "    SimilarityEngine,\n",
    ")\n",
    "from gest.service.evaluation.graph_matching.solver import SolverType\n",
    "from gest.service.evaluation.graph_matching.embedding_type_enum import EmbeddingType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e68a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_CSV_PATH = (\n",
    "    \"/workspaces/GEST/notebooks/data/manual_vs_synthetic_evaluation_graph_matching.csv\"\n",
    ")\n",
    "NEG_RESULTS_CSV_PATH = \"/workspaces/GEST/notebooks/data/manual_vs_synthetic_evaluation_graph_matching_negatives.csv\"\n",
    "\n",
    "REQUIRED_COLUMNS = {\"dataset\", \"id\", \"gest\"}\n",
    "EVAL_NEG_PER_POS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6461a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = pd.read_csv(\"/workspaces/GEST/data/gest_manual.csv\")\n",
    "synthetic = pd.read_csv(\"/workspaces/GEST/data/gest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a332a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_required_columns(df: pd.DataFrame, name: str, required_columns: set):\n",
    "    missing = required_columns - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{name} is missing required columns: {sorted(missing)}\")\n",
    "\n",
    "\n",
    "def ensure_unique_pairs(df: pd.DataFrame, name: str):\n",
    "    dup = df.duplicated([\"dataset\", \"id\"], keep=False)\n",
    "    if dup.any():\n",
    "        d = df.loc[dup, [\"dataset\", \"id\"]].value_counts().reset_index(name=\"count\")\n",
    "        raise ValueError(\n",
    "            f\"{name} contains duplicated (dataset, id) pairs. Expected unique.\\n\"\n",
    "            f\"Found {len(d)} duplicates:\\n{d.to_string(index=False)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56210f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_required_columns(manual, \"manual\", REQUIRED_COLUMNS)\n",
    "ensure_required_columns(synthetic, \"synthetic\", REQUIRED_COLUMNS)\n",
    "\n",
    "ensure_unique_pairs(manual, \"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81846cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 matching pairs to evaluate.\n"
     ]
    }
   ],
   "source": [
    "pairs = pd.merge(\n",
    "    manual[[\"dataset\", \"id\", \"gest\"]].rename(columns={\"gest\": \"gest_manual\"}),\n",
    "    synthetic[[\"dataset\", \"id\", \"gest\"]].rename(columns={\"gest\": \"gest_synthetic\"}),\n",
    "    on=[\"dataset\", \"id\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "print(f\"Found {len(pairs)} matching pairs to evaluate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0630bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Manual GESTs: 100%|██████████| 152/152 [00:00<00:00, 1689.96it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Parsing Manual GESTs\")\n",
    "pairs[\"g1\"] = pairs[\"gest_manual\"].progress_apply(\n",
    "    lambda s: GESTGraph(gest=GEST.model_validate_json(s))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9c3b205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Synthetic GESTs: 100%|██████████| 152/152 [00:00<00:00, 3139.05it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Parsing Synthetic GESTs\")\n",
    "pairs[\"g2\"] = pairs[\"gest_synthetic\"].progress_apply(\n",
    "    lambda s: GESTGraph(gest=GEST.model_validate_json(s))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe78e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    {\n",
    "        \"name\": \"Spectral_GloVe50\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.SPECTRAL,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE50,\n",
    "            \"use_edges\": True,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NGM_GloVe50\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.NGM,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE50,\n",
    "            \"use_edges\": True,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Spectral_GloVe50_NoEdges\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.SPECTRAL,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE50,\n",
    "            \"use_edges\": False,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Spectral_GloVe300\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.SPECTRAL,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE300,\n",
    "            \"use_edges\": True,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NGM_GloVe300\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.NGM,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE300,\n",
    "            \"use_edges\": True,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Spectral_GloVe300_NoEdges\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.SPECTRAL,\n",
    "            \"embedding_type\": EmbeddingType.GLOVE300,\n",
    "            \"use_edges\": False,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Spectral_W2V300\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.SPECTRAL,\n",
    "            \"embedding_type\": EmbeddingType.W2V_GOOGLE,\n",
    "            \"use_edges\": True,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NGM_W2V300\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.NGM,\n",
    "            \"embedding_type\": EmbeddingType.W2V_GOOGLE,\n",
    "            \"use_edges\": True,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Spectral_W2V300_NoEdges\",\n",
    "        \"engine_params\": {\n",
    "            \"solver_type\": SolverType.SPECTRAL,\n",
    "            \"embedding_type\": EmbeddingType.W2V_GOOGLE,\n",
    "            \"use_edges\": False,\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638112fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Evaluation for 'Spectral_GloVe50'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'Spectral_GloVe50' are already processed. Skipping.\n",
      "\n",
      "Starting Evaluation for 'NGM_GloVe50'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'NGM_GloVe50' are already processed. Skipping.\n",
      "\n",
      "Starting Evaluation for 'Spectral_GloVe50_NoEdges'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'Spectral_GloVe50_NoEdges' are already processed. Skipping.\n",
      "\n",
      "Starting Evaluation for 'Spectral_GloVe300'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'Spectral_GloVe300' are already processed. Skipping.\n",
      "\n",
      "Starting Evaluation for 'NGM_GloVe300'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'NGM_GloVe300' are already processed. Skipping.\n",
      "\n",
      "Starting Evaluation for 'Spectral_GloVe300_NoEdges'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'Spectral_GloVe300_NoEdges' are already processed. Skipping.\n",
      "\n",
      "Starting Evaluation for 'Spectral_W2V300'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'Spectral_W2V300' are already processed. Skipping.\n",
      "\n",
      "Starting Evaluation for 'NGM_W2V300'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'NGM_W2V300' are already processed. Skipping.\n",
      "\n",
      "Starting Evaluation for 'Spectral_W2V300_NoEdges'.\n",
      "Found 143 previously computed results for this configuration.\n",
      "All pairs for 'Spectral_W2V300_NoEdges' are already processed. Skipping.\n"
     ]
    }
   ],
   "source": [
    "for config in configurations:\n",
    "    config_name = config[\"name\"]\n",
    "    print(f\"\\nStarting Evaluation for '{config_name}'.\")\n",
    "\n",
    "    processed_pairs = set()\n",
    "    if os.path.exists(RESULTS_CSV_PATH):\n",
    "        temp_df = pd.read_csv(RESULTS_CSV_PATH)\n",
    "        processed_for_config = temp_df[temp_df[\"configuration\"] == config_name]\n",
    "        processed_pairs = set(\n",
    "            zip(processed_for_config[\"dataset\"], processed_for_config[\"id\"])\n",
    "        )\n",
    "\n",
    "    if processed_pairs:\n",
    "        print(\n",
    "            f\"Found {len(processed_pairs)} previously computed results for this configuration.\"\n",
    "        )\n",
    "\n",
    "    pairs[\"is_processed\"] = [\n",
    "        (d, i) in processed_pairs for d, i in zip(pairs[\"dataset\"], pairs[\"id\"])\n",
    "    ]\n",
    "    pairs_to_process = pairs[~pairs[\"is_processed\"]].copy()\n",
    "\n",
    "    if pairs_to_process.empty:\n",
    "        print(f\"All pairs for '{config_name}' are already processed. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {len(pairs_to_process)} new pairs for '{config_name}'.\")\n",
    "    engine = SimilarityEngine(**config[\"engine_params\"])\n",
    "    similarity_service = SimilarityService(engine=engine)\n",
    "\n",
    "    def compute_similarity(row) -> float:\n",
    "        try:\n",
    "            return similarity_service.graph_similarity_normalized(row[\"g1\"], row[\"g2\"])\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Exception occurred on (dataset={row['dataset']}, id={row['id']}): \\n{e}\"\n",
    "            )\n",
    "            return 0.0\n",
    "\n",
    "    csv_header = [\"dataset\", \"id\", \"configuration\", \"similarity\"]\n",
    "    write_header = not os.path.exists(RESULTS_CSV_PATH)\n",
    "\n",
    "    with open(RESULTS_CSV_PATH, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=csv_header)\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "\n",
    "        for _, row in tqdm(\n",
    "            pairs_to_process.iterrows(),\n",
    "            total=len(pairs_to_process),\n",
    "            desc=f\"Calculating for {config_name}\",\n",
    "        ):\n",
    "            score = compute_similarity(row)\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"dataset\": row[\"dataset\"],\n",
    "                    \"id\": row[\"id\"],\n",
    "                    \"configuration\": config_name,\n",
    "                    \"similarity\": score,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f80e6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_score(pos_vals: pd.Series, neg_vals: pd.Series) -> float:\n",
    "    mu1, mu0 = pos_vals.mean(), neg_vals.mean()\n",
    "    v1, v0 = pos_vals.var(ddof=1), neg_vals.var(ddof=1)\n",
    "    return float(((mu1 - mu0) ** 2) / (v1 + v0 + 1e-12))\n",
    "\n",
    "\n",
    "def pr_auc(scores: pd.Series, labels: pd.Series) -> float:\n",
    "    return float(average_precision_score(labels, scores))\n",
    "\n",
    "\n",
    "def top1_accuracy(df: pd.DataFrame, score_col: str) -> float:\n",
    "    hits = []\n",
    "    for _, g in df.groupby([\"dataset\", \"id\"]):\n",
    "        if g[\"label\"].sum() == len(g):\n",
    "            continue\n",
    "        g = g.sort_values(score_col, ascending=False)\n",
    "        hits.append(int(g.iloc[0][\"label\"] == 1))\n",
    "    return float(np.mean(hits)) if hits else float(\"nan\")\n",
    "\n",
    "\n",
    "def point_biserial_corr(scores: pd.Series, labels: pd.Series) -> float:\n",
    "    s = scores.to_numpy(dtype=float)\n",
    "    y = labels.to_numpy(dtype=float)\n",
    "    if s.std() < 1e-12 or y.std() < 1e-12:\n",
    "        return float(\"nan\")\n",
    "    return float(np.corrcoef(s, y)[0, 1])\n",
    "\n",
    "\n",
    "def _stable_rng(dataset: str, ex_id: str, seed: int = 0) -> np.random.Generator:\n",
    "    h = hashlib.sha256(f\"{dataset}::{ex_id}::{seed}\".encode()).digest()\n",
    "    return np.random.default_rng(int.from_bytes(h[:4], \"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2163916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _neg_pairs_for_keys(\n",
    "    pairs_df: pd.DataFrame, subset_keys, neg_per_pos: int\n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "    by_ds = {ds: grp.sort_values(\"id\") for ds, grp in pairs_df.groupby(\"dataset\")}\n",
    "    for ds, ex_id in subset_keys:\n",
    "        ex_id = str(ex_id)\n",
    "        grp = by_ds.get(ds)\n",
    "        if grp is None or len(grp) < 2:\n",
    "            continue\n",
    "        candidates = [str(i) for i in grp[\"id\"].tolist() if str(i) != ex_id]\n",
    "        if not candidates:\n",
    "            continue\n",
    "        rng = _stable_rng(ds, ex_id)\n",
    "        k = min(neg_per_pos, len(candidates))\n",
    "        choose = rng.choice(candidates, size=k, replace=len(candidates) < k)\n",
    "        for neg_id in np.atleast_1d(choose):\n",
    "            rows.append({\"dataset\": ds, \"id\": ex_id, \"neg_id\": str(neg_id)})\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e943a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_all = pairs[[\"dataset\", \"id\", \"g1\", \"g2\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab055868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_negative_scores_cached(\n",
    "    config_name: str, engine_params: dict, keys\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Cache negative scores for desired (dataset,id) keys and return the subset.\"\"\"\n",
    "    if os.path.exists(NEG_RESULTS_CSV_PATH):\n",
    "        neg_cache = pd.read_csv(NEG_RESULTS_CSV_PATH)\n",
    "        neg_cache[\"id\"] = neg_cache[\"id\"].astype(str)\n",
    "        neg_cache[\"neg_id\"] = neg_cache[\"neg_id\"].astype(str)\n",
    "    else:\n",
    "        neg_cache = pd.DataFrame(\n",
    "            columns=[\"dataset\", \"id\", \"neg_id\", \"configuration\", \"similarity\"]\n",
    "        )\n",
    "\n",
    "    have = (\n",
    "        neg_cache[neg_cache[\"configuration\"] == config_name]\n",
    "        if len(neg_cache)\n",
    "        else neg_cache\n",
    "    )\n",
    "    have_keys = set(zip(have[\"dataset\"], have[\"id\"], have[\"neg_id\"]))\n",
    "\n",
    "    desired_pairs = _neg_pairs_for_keys(pairs_all, keys, EVAL_NEG_PER_POS)\n",
    "    if desired_pairs.empty:\n",
    "        return have\n",
    "\n",
    "    desired_keys = set(\n",
    "        zip(desired_pairs[\"dataset\"], desired_pairs[\"id\"], desired_pairs[\"neg_id\"])\n",
    "    )\n",
    "    to_compute_keys = desired_keys - have_keys\n",
    "\n",
    "    if to_compute_keys:\n",
    "        g1_map = {\n",
    "            (d, str(i)): g\n",
    "            for d, i, g in pairs_all[[\"dataset\", \"id\", \"g1\"]].itertuples(index=False)\n",
    "        }\n",
    "        g2_map = {\n",
    "            (d, str(i)): g\n",
    "            for d, i, g in pairs_all[[\"dataset\", \"id\", \"g2\"]].itertuples(index=False)\n",
    "        }\n",
    "\n",
    "        engine = SimilarityEngine(**engine_params)\n",
    "        sim = SimilarityService(engine=engine)\n",
    "\n",
    "        print(\n",
    "            f\"Processing {len(to_compute_keys)} new negative pairs for '{config_name}'.\"\n",
    "        )\n",
    "        rows = []\n",
    "        for ds, ex_id, neg_id in tqdm(\n",
    "            list(to_compute_keys),\n",
    "            total=len(to_compute_keys),\n",
    "            desc=f\"Negatives for {config_name}\",\n",
    "        ):\n",
    "            try:\n",
    "                g1 = g1_map[(ds, str(ex_id))]\n",
    "                g2 = g2_map[(ds, str(neg_id))]\n",
    "                score = sim.graph_similarity_normalized(g1, g2)\n",
    "            except Exception:\n",
    "                score = 0.0\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"dataset\": ds,\n",
    "                    \"id\": str(ex_id),\n",
    "                    \"neg_id\": str(neg_id),\n",
    "                    \"configuration\": config_name,\n",
    "                    \"similarity\": score,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        write_header = not os.path.exists(NEG_RESULTS_CSV_PATH)\n",
    "        with open(NEG_RESULTS_CSV_PATH, \"a\", newline=\"\") as f:\n",
    "            w = csv.DictWriter(\n",
    "                f, fieldnames=[\"dataset\", \"id\", \"neg_id\", \"configuration\", \"similarity\"]\n",
    "            )\n",
    "            if write_header:\n",
    "                w.writeheader()\n",
    "            for r in rows:\n",
    "                w.writerow(r)\n",
    "\n",
    "        neg_cache = pd.read_csv(NEG_RESULTS_CSV_PATH)\n",
    "        neg_cache[\"id\"] = neg_cache[\"id\"].astype(str)\n",
    "        neg_cache[\"neg_id\"] = neg_cache[\"neg_id\"].astype(str)\n",
    "\n",
    "    neg_sub = neg_cache[neg_cache[\"configuration\"] == config_name]\n",
    "    return neg_sub.merge(desired_pairs, on=[\"dataset\", \"id\", \"neg_id\"], how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc4fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Evaluation for 'Spectral_GloVe50' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n",
      "\n",
      "Starting Evaluation for 'NGM_GloVe50' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n",
      "\n",
      "Starting Evaluation for 'Spectral_GloVe50_NoEdges' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n",
      "\n",
      "Starting Evaluation for 'Spectral_GloVe300' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n",
      "\n",
      "Starting Evaluation for 'NGM_GloVe300' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n",
      "\n",
      "Starting Evaluation for 'Spectral_GloVe300_NoEdges' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n",
      "\n",
      "Starting Evaluation for 'Spectral_W2V300' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n",
      "\n",
      "Starting Evaluation for 'NGM_W2V300' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n",
      "\n",
      "Starting Evaluation for 'Spectral_W2V300_NoEdges' (negatives & metrics).\n",
      "Found 572 previously computed negative results for this configuration.\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv(RESULTS_CSV_PATH)\n",
    "summary_rows = []\n",
    "\n",
    "for config in configurations:\n",
    "    name = config[\"name\"]\n",
    "\n",
    "    pos_scores_df = results_df[results_df[\"configuration\"] == name][\n",
    "        [\"dataset\", \"id\", \"similarity\"]\n",
    "    ].copy()\n",
    "    if pos_scores_df.empty:\n",
    "        print(f\"\\nStarting Evaluation for '{name}'.\")\n",
    "        print(\"Found 0 previously computed results for this configuration.\")\n",
    "        print(f\"All pairs for '{name}' are already processed. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nStarting Evaluation for '{name}' (negatives & metrics).\")\n",
    "    keys = set(zip(pos_scores_df[\"dataset\"], pos_scores_df[\"id\"].astype(str)))\n",
    "\n",
    "    existing = (\n",
    "        pd.read_csv(NEG_RESULTS_CSV_PATH)\n",
    "        if os.path.exists(NEG_RESULTS_CSV_PATH)\n",
    "        else pd.DataFrame(\n",
    "            columns=[\"dataset\", \"id\", \"neg_id\", \"configuration\", \"similarity\"]\n",
    "        )\n",
    "    )\n",
    "    existing = existing[(existing[\"configuration\"] == name)]\n",
    "    existing[\"id\"] = existing[\"id\"].astype(str)\n",
    "    existing[\"neg_id\"] = existing[\"neg_id\"].astype(str)\n",
    "    already = existing.merge(\n",
    "        _neg_pairs_for_keys(pairs_all, keys, EVAL_NEG_PER_POS),\n",
    "        on=[\"dataset\", \"id\", \"neg_id\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    print(\n",
    "        f\"Found {len(already)} previously computed negative results for this configuration.\"\n",
    "    )\n",
    "\n",
    "    neg_cached = _ensure_negative_scores_cached(name, config[\"engine_params\"], keys)\n",
    "\n",
    "    pos_scores_df = pos_scores_df.rename(columns={\"similarity\": \"score\"}).copy()\n",
    "    pos_scores_df[\"id\"] = pos_scores_df[\"id\"].astype(str)\n",
    "    pos_scores_df[\"label\"] = 1\n",
    "\n",
    "    neg_scores_df = (\n",
    "        neg_cached[[\"dataset\", \"id\", \"neg_id\", \"similarity\"]]\n",
    "        .rename(columns={\"similarity\": \"score\"})\n",
    "        .copy()\n",
    "    )\n",
    "    neg_scores_df[\"id\"] = neg_scores_df[\"id\"].astype(str)\n",
    "    neg_scores_df[\"label\"] = 0\n",
    "\n",
    "    eval_df = pd.concat(\n",
    "        [\n",
    "            pos_scores_df[[\"dataset\", \"id\", \"label\", \"score\"]],\n",
    "            neg_scores_df[[\"dataset\", \"id\", \"label\", \"score\"]],\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    corr = 100.0 * point_biserial_corr(eval_df[\"score\"], eval_df[\"label\"])\n",
    "    acc = 100.0 * top1_accuracy(eval_df, \"score\")\n",
    "    fsc = fisher_score(pos_scores_df[\"score\"], neg_scores_df[\"score\"])\n",
    "    auc = 100.0 * pr_auc(eval_df[\"score\"], eval_df[\"label\"])\n",
    "\n",
    "    summary_rows.append(\n",
    "        {\"Configuration\": name, \"Corr\": corr, \"Acc\": acc, \"F\": fsc, \"AUC\": auc}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "372a68b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation metrics for each experiment:\n",
      "------------------------------------\n",
      "                             Corr     Acc      F     AUC\n",
      "Configuration                                           \n",
      "NGM_GloVe300               75.356  87.413  1.731  87.614\n",
      "NGM_GloVe50                73.927  83.217  1.749  83.498\n",
      "NGM_W2V300                 53.988  66.434  0.740  63.612\n",
      "Spectral_GloVe300          73.919  88.811  2.383  87.168\n",
      "Spectral_GloVe300_NoEdges  65.217  88.112  2.564  81.306\n",
      "Spectral_GloVe50           53.980  76.224  1.252  69.330\n",
      "Spectral_GloVe50_NoEdges   53.927  88.112  1.449  79.441\n",
      "Spectral_W2V300            31.085  53.147  0.311  37.804\n",
      "Spectral_W2V300_NoEdges    16.109  76.923  0.108  35.641\n"
     ]
    }
   ],
   "source": [
    "eval_summary = (\n",
    "    pd.DataFrame(summary_rows).sort_values(\"Configuration\").set_index(\"Configuration\")\n",
    ")\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "print(\"\\nEvaluation metrics for each experiment:\")\n",
    "print(\"------------------------------------\")\n",
    "print(eval_summary.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
